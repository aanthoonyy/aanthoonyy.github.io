<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Evaluating LLMs â€” Anthony Devito</title>
    <link rel="stylesheet" href="../styles.css" />
  </head>
  <body>
    <header>
      <nav>
        <a href="../index.html" class="nav-name">Anthony Devito</a>
        <ul class="nav-links">
          <li><a href="../index.html#about">About</a></li>
          <li><a href="../index.html#experience">Experience</a></li>
          <li><a href="../index.html#projects">Projects</a></li>
        </ul>
      </nav>
    </header>

    <main>
      <div class="container">
        <div class="article-header">
          <a href="../index.html#projects" class="back-link">&larr; Projects</a>
          <h1>evaluating technical capabilities of llms</h1>
          <div class="article-meta">
            Benchmarking and evaluation of large language models
          </div>
          <a
            href="https://github.com/aanthoonyy/Evaluating-Technical-Capabilities-of-LLMs"
            target="_blank"
          >
            ðŸ”— GitHub Repository
          </a>
        </div>

        <div class="article-body">
          <p>
            This is a research project a friend and I did as apart of our Data
            Science class. The goal was to take the common LLM models (~late
            2024) and figure out which ones preformed best at different tasks.
            The tasks included, Performance of Random String Identification,
            Performance of Random String Generation, Performance of Multi-step
            problem solving, and Performance of Complex Calculations. From our
            research, google/gemma-2-27b-it emerged as the most specialized
            model for random string generation, outperforming other models in
            this task. In the complex calculations category,
            meta-llama/llama-3.1-70b-instruct demonstrated exceptional
            capabilities, highlighting its strength in mathematical
            problem-solving. For random string identification, x-ai/grok-beta
            stood out as the most specialized model, showcasing its ability to
            distinguish between random and non-random strings. Finally,
            google/gemini-flash-1.5 excelled in multistep problems,
            demonstrating its capacity to break down complex tasks into
            manageable steps.
          </p>
          <a href="llms-eval.pdf" target="_blank"
            >For more info and graphs, check out our paper! (PDF)</a
          >
        </div>
      </div>
    </main>

    <footer>
      <div class="container">
        <p>
          &copy; 2026 Anthony Devito &mdash;
          <a href="https://github.com/aanthoonyy">GitHub</a>
        </p>
      </div>
    </footer>
  </body>
</html>
